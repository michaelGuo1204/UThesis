
@article{martel-pelletier_osteoarthritis_2016,
	title = {Osteoarthritis},
	volume = {2},
	issn = {2056-676X},
	url = {http://www.nature.com/articles/nrdp201672},
	doi = {10.1038/nrdp.2016.72},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Nature Reviews Disease Primers},
	author = {Martel-Pelletier, Johanne and Barr, Andrew J. and Cicuttini, Flavia M. and Conaghan, Philip G. and Cooper, Cyrus and Goldring, Mary B. and Goldring, Steven R. and Jones, Graeme and Teichtahl, Andrew J. and Pelletier, Jean-Pierre},
	month = dec,
	year = {2016},
	pages = {16072},
}

@article{james_global_2018,
	title = {Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the {Global} {Burden} of {Disease} {Study} 2017},
	volume = {392},
	issn = {01406736},
	shorttitle = {Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673618322797},
	doi = {10.1016/S0140-6736(18)32279-7},
	language = {en},
	number = {10159},
	urldate = {2022-06-08},
	journal = {The Lancet},
	author = {James, Spencer L and Abate, Degu and Abate, Kalkidan Hassen and Abay, Solomon M and Abbafati, Cristiana and Abbasi, Nooshin and Abbastabar, Hedayat and Abd-Allah, Foad and Abdela, Jemal and Abdelalim, Ahmed and Abdollahpour, Ibrahim and Abdulkader, Rizwan Suliankatchi and Abebe, Zegeye and Abera, Semaw F and Abil, Olifan Zewdie and Abraha, Haftom Niguse and Abu-Raddad, Laith Jamal and Abu-Rmeileh, Niveen M E and Accrombessi, Manfred Mario Kokou and Acharya, Dilaram and Acharya, Pawan and Ackerman, Ilana N and Adamu, Abdu A and Adebayo, Oladimeji M and Adekanmbi, Victor and Adetokunboh, Olatunji O and Adib, Mina G and Adsuar, Jose C and Afanvi, Kossivi Agbelenko and Afarideh, Mohsen and Afshin, Ashkan and Agarwal, Gina and Agesa, Kareha M and Aggarwal, Rakesh and Aghayan, Sargis Aghasi and Agrawal, Sutapa and Ahmadi, Alireza and Ahmadi, Mehdi and Ahmadieh, Hamid and Ahmed, Muktar Beshir and Aichour, Amani Nidhal and Aichour, Ibtihel and Aichour, Miloud Taki Eddine and Akinyemiju, Tomi and Akseer, Nadia and Al-Aly, Ziyad and Al-Eyadhy, Ayman and Al-Mekhlafi, Hesham M and Al-Raddadi, Rajaa M and Alahdab, Fares and Alam, Khurshid and Alam, Tahiya and Alashi, Alaa and Alavian, Seyed Moayed and Alene, Kefyalew Addis and Alijanzadeh, Mehran and Alizadeh-Navaei, Reza and Aljunid, Syed Mohamed and Alkerwi, Ala'a and Alla, François and Allebeck, Peter and Alouani, Mohamed M L and Altirkawi, Khalid and Alvis-Guzman, Nelson and Amare, Azmeraw T and Aminde, Leopold N and Ammar, Walid and Amoako, Yaw Ampem and Anber, Nahla Hamed and Andrei, Catalina Liliana and Androudi, Sofia and Animut, Megbaru Debalkie and Anjomshoa, Mina and Ansha, Mustafa Geleto and Antonio, Carl Abelardo T and Anwari, Palwasha and Arabloo, Jalal and Arauz, Antonio and Aremu, Olatunde and Ariani, Filippo and Armoon, Bahroom and Ärnlöv, Johan and Arora, Amit and Artaman, Al and Aryal, Krishna K and Asayesh, Hamid and Asghar, Rana Jawad and Ataro, Zerihun and Atre, Sachin R and Ausloos, Marcel and Avila-Burgos, Leticia and Avokpaho, Euripide F G A and Awasthi, Ashish and Ayala Quintanilla, Beatriz Paulina and Ayer, Rakesh and Azzopardi, Peter S and Babazadeh, Arefeh and Badali, Hamid and Badawi, Alaa and Bali, Ayele Geleto and Ballesteros, Katherine E and Ballew, Shoshana H and Banach, Maciej and Banoub, Joseph Adel Mattar and Banstola, Amrit and Barac, Aleksandra and Barboza, Miguel A and Barker-Collo, Suzanne Lyn and Bärnighausen, Till Winfried and Barrero, Lope H and Baune, Bernhard T and Bazargan-Hejazi, Shahrzad and Bedi, Neeraj and Beghi, Ettore and Behzadifar, Masoud and Behzadifar, Meysam and Béjot, Yannick and Belachew, Abate Bekele and Belay, Yihalem Abebe and Bell, Michelle L and Bello, Aminu K and Bensenor, Isabela M and Bernabe, Eduardo and Bernstein, Robert S and Beuran, Mircea and Beyranvand, Tina and Bhala, Neeraj and Bhattarai, Suraj and Bhaumik, Soumyadeep and Bhutta, Zulfiqar A and Biadgo, Belete and Bijani, Ali and Bikbov, Boris and Bilano, Ver and Bililign, Nigus and Bin Sayeed, Muhammad Shahdaat and Bisanzio, Donal and Blacker, Brigette F and Blyth, Fiona M and Bou-Orm, Ibrahim R and Boufous, Soufiane and Bourne, Rupert and Brady, Oliver J and Brainin, Michael and Brant, Luisa C and Brazinova, Alexandra and Breitborde, Nicholas J K and Brenner, Hermann and Briant, Paul Svitil and Briggs, Andrew M and Briko, Andrey Nikolaevich and Britton, Gabrielle and Brugha, Traolach and Buchbinder, Rachelle and Busse, Reinhard and Butt, Zahid A and Cahuana-Hurtado, Lucero and Cano, Jorge and Cárdenas, Rosario and Carrero, Juan J and Carter, Austin and Carvalho, Félix and Castañeda-Orjuela, Carlos A and Castillo Rivas, Jacqueline and Castro, Franz and Catalá-López, Ferrán and Cercy, Kelly M and Cerin, Ester and Chaiah, Yazan and Chang, Alex R and Chang, Hsing-Yi and Chang, Jung-Chen and Charlson, Fiona J and Chattopadhyay, Aparajita and Chattu, Vijay Kumar and Chaturvedi, Pankaj and Chiang, Peggy Pei-Chia and Chin, Ken Lee and Chitheer, Abdulaal and Choi, Jee-Young J and Chowdhury, Rajiv and Christensen, Hanne and Christopher, Devasahayam J and Cicuttini, Flavia M and Ciobanu, Liliana G and Cirillo, Massimo and Claro, Rafael M and Collado-Mateo, Daniel and Cooper, Cyrus and Coresh, Josef and Cortesi, Paolo Angelo and Cortinovis, Monica and Costa, Megan and Cousin, Ewerton and Criqui, Michael H and Cromwell, Elizabeth A and Cross, Marita and Crump, John A and Dadi, Abel Fekadu and Dandona, Lalit and Dandona, Rakhi and Dargan, Paul I and Daryani, Ahmad and Das Gupta, Rajat and Das Neves, José and Dasa, Tamirat Tesfaye and Davey, Gail and Davis, Adrian C and Davitoiu, Dragos Virgil and De Courten, Barbora and De La Hoz, Fernando Pio and De Leo, Diego and De Neve, Jan-Walter and Degefa, Meaza Girma and Degenhardt, Louisa and Deiparine, Selina and Dellavalle, Robert P and Demoz, Gebre Teklemariam and Deribe, Kebede and Dervenis, Nikolaos and Des Jarlais, Don C and Dessie, Getenet Ayalew and Dey, Subhojit and Dharmaratne, Samath Dhamminda and Dinberu, Mesfin Tadese and Dirac, M Ashworth and Djalalinia, Shirin and Doan, Linh and Dokova, Klara and Doku, David Teye and Dorsey, E Ray and Doyle, Kerrie E and Driscoll, Tim Robert and Dubey, Manisha and Dubljanin, Eleonora and Duken, Eyasu Ejeta and Duncan, Bruce B and Duraes, Andre R and Ebrahimi, Hedyeh and Ebrahimpour, Soheil and Echko, Michelle Marie and Edvardsson, David and Effiong, Andem and Ehrlich, Joshua R and El Bcheraoui, Charbel and El Sayed Zaki, Maysaa and El-Khatib, Ziad and Elkout, Hajer and Elyazar, Iqbal R F and Enayati, Ahmadali and Endries, Aman Yesuf and Er, Benjamin and Erskine, Holly E and Eshrati, Babak and Eskandarieh, Sharareh and Esteghamati, Alireza and Esteghamati, Sadaf and Fakhim, Hamed and Fallah Omrani, Vahid and Faramarzi, Mahbobeh and Fareed, Mohammad and Farhadi, Farzaneh and Farid, Talha A and Farinha, Carla Sofia E sá and Farioli, Andrea and Faro, Andre and Farvid, Maryam S and Farzadfar, Farshad and Feigin, Valery L and Fentahun, Netsanet and Fereshtehnejad, Seyed-Mohammad and Fernandes, Eduarda and Fernandes, Joao C and Ferrari, Alize J and Feyissa, Garumma Tolu and Filip, Irina and Fischer, Florian and Fitzmaurice, Christina and Foigt, Nataliya A and Foreman, Kyle J and Fox, Jack and Frank, Tahvi D and Fukumoto, Takeshi and Fullman, Nancy and Fürst, Thomas and Furtado, João M and Futran, Neal D and Gall, Seana and Ganji, Morsaleh and Gankpe, Fortune Gbetoho and Garcia-Basteiro, Alberto L and Gardner, William M and Gebre, Abadi Kahsu and Gebremedhin, Amanuel Tesfay and Gebremichael, Teklu Gebrehiwo and Gelano, Tilayie Feto and Geleijnse, Johanna M and Genova-Maleras, Ricard and Geramo, Yilma Chisha Dea and Gething, Peter W and Gezae, Kebede Embaye and Ghadiri, Keyghobad and Ghasemi Falavarjani, Khalil and Ghasemi-Kasman, Maryam and Ghimire, Mamata and Ghosh, Rakesh and Ghoshal, Aloke Gopal and Giampaoli, Simona and Gill, Paramjit Singh and Gill, Tiffany K and Ginawi, Ibrahim Abdelmageed and Giussani, Giorgia and Gnedovskaya, Elena V and Goldberg, Ellen M and Goli, Srinivas and Gómez-Dantés, Hector and Gona, Philimon N and Gopalani, Sameer Vali and Gorman, Taren M and Goulart, Alessandra C and Goulart, Bárbara Niegia Garcia and Grada, Ayman and Grams, Morgan E and Grosso, Giuseppe and Gugnani, Harish Chander and Guo, Yuming and Gupta, Prakash C and Gupta, Rahul and Gupta, Rajeev and Gupta, Tanush and Gyawali, Bishal and Haagsma, Juanita A and Hachinski, Vladimir and Hafezi-Nejad, Nima and Haghparast Bidgoli, Hassan and Hagos, Tekleberhan B and Hailu, Gessessew Bugssa and Haj-Mirzaian, Arvin and Haj-Mirzaian, Arya and Hamadeh, Randah R and Hamidi, Samer and Handal, Alexis J and Hankey, Graeme J and Hao, Yuantao and Harb, Hilda L and Harikrishnan, Sivadasanpillai and Haro, Josep Maria and Hasan, Mehedi and Hassankhani, Hadi and Hassen, Hamid Yimam and Havmoeller, Rasmus and Hawley, Caitlin N and Hay, Roderick J and Hay, Simon I and Hedayatizadeh-Omran, Akbar and Heibati, Behzad and Hendrie, Delia and Henok, Andualem and Herteliu, Claudiu and Heydarpour, Sousan and Hibstu, Desalegn Tsegaw and Hoang, Huong Thanh and Hoek, Hans W and Hoffman, Howard J and Hole, Michael K and Homaie Rad, Enayatollah and Hoogar, Praveen and Hosgood, H Dean and Hosseini, Seyed Mostafa and Hosseinzadeh, Mehdi and Hostiuc, Mihaela and Hostiuc, Sorin and Hotez, Peter J and Hoy, Damian G and Hsairi, Mohamed and Htet, Aung Soe and Hu, Guoqing and Huang, John J and Huynh, Chantal K and Iburg, Kim Moesgaard and Ikeda, Chad Thomas and Ileanu, Bogdan and Ilesanmi, Olayinka Stephen and Iqbal, Usman and Irvani, Seyed Sina Naghibi and Irvine, Caleb Mackay Salpeter and Islam, Sheikh Mohammed Shariful and Islami, Farhad and Jacobsen, Kathryn H and Jahangiry, Leila and Jahanmehr, Nader and Jain, Sudhir Kumar and Jakovljevic, Mihajlo and Javanbakht, Mehdi and Jayatilleke, Achala Upendra and Jeemon, Panniyammakal and Jha, Ravi Prakash and Jha, Vivekanand and Ji, John S and Johnson, Catherine O and Jonas, Jost B and Jozwiak, Jacek Jerzy and Jungari, Suresh Banayya and Jürisson, Mikk and Kabir, Zubair and Kadel, Rajendra and Kahsay, Amaha and Kalani, Rizwan and Kanchan, Tanuj and Karami, Manoochehr and Karami Matin, Behzad and Karch, André and Karema, Corine and Karimi, Narges and Karimi, Seyed M and Kasaeian, Amir and Kassa, Dessalegn H and Kassa, Getachew Mullu and Kassa, Tesfaye Dessale and Kassebaum, Nicholas J and Katikireddi, Srinivasa Vittal and Kawakami, Norito and Karyani, Ali Kazemi and Keighobadi, Masoud Masoud and Keiyoro, Peter Njenga and Kemmer, Laura and Kemp, Grant Rodgers and Kengne, Andre Pascal and Keren, Andre and Khader, Yousef Saleh and Khafaei, Behzad and Khafaie, Morteza Abdullatif and Khajavi, Alireza and Khalil, Ibrahim A and Khan, Ejaz Ahmad and Khan, Muhammad Shahzeb and Khan, Muhammad Ali and Khang, Young-Ho and Khazaei, Mohammad and Khoja, Abdullah T and Khosravi, Ardeshir and Khosravi, Mohammad Hossein and Kiadaliri, Aliasghar A and Kiirithio, Daniel N and Kim, Cho-Il and Kim, Daniel and Kim, Pauline and Kim, Young-Eun and Kim, Yun Jin and Kimokoti, Ruth W and Kinfu, Yohannes and Kisa, Adnan and Kissimova-Skarbek, Katarzyna and Kivimäki, Mika and Knudsen, Ann Kristin Skrindo and Kocarnik, Jonathan M and Kochhar, Sonali and Kokubo, Yoshihiro and Kolola, Tufa and Kopec, Jacek A and Kosen, Soewarta and Kotsakis, Georgios A and Koul, Parvaiz A and Koyanagi, Ai and Kravchenko, Michael A and Krishan, Kewal and Krohn, Kristopher J and Kuate Defo, Barthelemy and Kucuk Bicer, Burcu and Kumar, G Anil and Kumar, Manasi and Kyu, Hmwe Hmwe and Lad, Deepesh P and Lad, Sheetal D and Lafranconi, Alessandra and Lalloo, Ratilal and Lallukka, Tea and Lami, Faris Hasan and Lansingh, Van C and Latifi, Arman and Lau, Kathryn Mei-Ming and Lazarus, Jeffrey V and Leasher, Janet L and Ledesma, Jorge R and Lee, Paul H and Leigh, James and Leung, Janni and Levi, Miriam and Lewycka, Sonia and Li, Shanshan and Li, Yichong and Liao, Yu and Liben, Misgan Legesse and Lim, Lee-Ling and Lim, Stephen S and Liu, Shiwei and Lodha, Rakesh and Looker, Katharine J and Lopez, Alan D and Lorkowski, Stefan and Lotufo, Paulo A and Low, Nicola and Lozano, Rafael and Lucas, Tim C D and Lucchesi, Lydia R and Lunevicius, Raimundas and Lyons, Ronan A and Ma, Stefan and Macarayan, Erlyn Rachelle King and Mackay, Mark T and Madotto, Fabiana and Magdy Abd El Razek, Hassan and Magdy Abd El Razek, Muhammed and Maghavani, Dhaval P and Mahotra, Narayan Bahadur and Mai, Hue Thi and Majdan, Marek and Majdzadeh, Reza and Majeed, Azeem and Malekzadeh, Reza and Malta, Deborah Carvalho and Mamun, Abdullah A and Manda, Ana-Laura and Manguerra, Helena and Manhertz, Treh and Mansournia, Mohammad Ali and Mantovani, Lorenzo Giovanni and Mapoma, Chabila Christopher and Maravilla, Joemer C and Marcenes, Wagner and Marks, Ashley and Martins-Melo, Francisco Rogerlândio and Martopullo, Ira and März, Winfried and Marzan, Melvin B and Mashamba-Thompson, Tivani Phosa and Massenburg, Benjamin Ballard and Mathur, Manu Raj and Matsushita, Kunihiro and Maulik, Pallab K and Mazidi, Mohsen and McAlinden, Colm and McGrath, John J and McKee, Martin and Mehndiratta, Man Mohan and Mehrotra, Ravi and Mehta, Kala M and Mehta, Varshil and Mejia-Rodriguez, Fabiola and Mekonen, Tesfa and Melese, Addisu and Melku, Mulugeta and Meltzer, Michele and Memiah, Peter T N and Memish, Ziad A and Mendoza, Walter and Mengistu, Desalegn Tadese and Mengistu, Getnet and Mensah, George A and Mereta, Seid Tiku and Meretoja, Atte and Meretoja, Tuomo J and Mestrovic, Tomislav and Mezerji, Naser Mohammad Gholi and Miazgowski, Bartosz and Miazgowski, Tomasz and Millear, Anoushka I and Miller, Ted R and Miltz, Benjamin and Mini, G K and Mirarefin, Mojde and Mirrakhimov, Erkin M and Misganaw, Awoke Temesgen and Mitchell, Philip B and Mitiku, Habtamu and Moazen, Babak and Mohajer, Bahram and Mohammad, Karzan Abdulmuhsin and Mohammadifard, Noushin and Mohammadnia-Afrouzi, Mousa and Mohammed, Mohammed A and Mohammed, Shafiu and Mohebi, Farnam and Moitra, Modhurima and Mokdad, Ali H and Molokhia, Mariam and Monasta, Lorenzo and Moodley, Yoshan and Moosazadeh, Mahmood and Moradi, Ghobad and Moradi-Lakeh, Maziar and Moradinazar, Mehdi and Moraga, Paula and Morawska, Lidia and Moreno Velásquez, Ilais and Morgado-Da-Costa, Joana and Morrison, Shane Douglas and Moschos, Marilita M and Mountjoy-Venning, W Cliff and Mousavi, Seyyed Meysam and Mruts, Kalayu Brhane and Muche, Achenef Asmamaw and Muchie, Kindie Fentahun and Mueller, Ulrich Otto and Muhammed, Oumer Sada and Mukhopadhyay, Satinath and Muller, Kate and Mumford, John Everett and Murhekar, Manoj and Musa, Jonah and Musa, Kamarul Imran and Mustafa, Ghulam and Nabhan, Ashraf F and Nagata, Chie and Naghavi, Mohsen and Naheed, Aliya and Nahvijou, Azin and Naik, Gurudatta and Naik, Nitish and Najafi, Farid and Naldi, Luigi and Nam, Hae Sung and Nangia, Vinay and Nansseu, Jobert Richie and Nascimento, Bruno Ramos and Natarajan, Gopalakrishnan and Neamati, Nahid and Negoi, Ionut and Negoi, Ruxandra Irina and Neupane, Subas and Newton, Charles Richard James and Ngunjiri, Josephine W and Nguyen, Anh Quynh and Nguyen, Ha Thu and Nguyen, Huong Lan Thi and Nguyen, Huong Thanh and Nguyen, Long Hoang and Nguyen, Minh and Nguyen, Nam Ba and Nguyen, Son Hoang and Nichols, Emma and Ningrum, Dina Nur Anggraini and Nixon, Molly R and Nolutshungu, Nomonde and Nomura, Shuhei and Norheim, Ole F and Noroozi, Mehdi and Norrving, Bo and Noubiap, Jean Jacques and Nouri, Hamid Reza and Nourollahpour Shiadeh, Malihe and Nowroozi, Mohammad Reza and Nsoesie, Elaine O and Nyasulu, Peter S and Odell, Christopher M and Ofori-Asenso, Richard and Ogbo, Felix Akpojene and Oh, In-Hwan and Oladimeji, Olanrewaju and Olagunju, Andrew T and Olagunju, Tinuke O and Olivares, Pedro R and Olsen, Helen Elizabeth and Olusanya, Bolajoko Olubukunola and Ong, Kanyin L and Ong, Sok King and Oren, Eyal and Ortiz, Alberto and Ota, Erika and Otstavnov, Stanislav S and Øverland, Simon and Owolabi, Mayowa Ojo and P A, Mahesh and Pacella, Rosana and Pakpour, Amir H and Pana, Adrian and Panda-Jonas, Songhomitra and Parisi, Andrea and Park, Eun-Kee and Parry, Charles D H and Patel, Shanti and Pati, Sanghamitra and Patil, Snehal T and Patle, Ajay and Patton, George C and Paturi, Vishnupriya Rao and Paulson, Katherine R and Pearce, Neil and Pereira, David M and Perico, Norberto and Pesudovs, Konrad and Pham, Hai Quang and Phillips, Michael R and Pigott, David M and Pillay, Julian David and Piradov, Michael A and Pirsaheb, Meghdad and Pishgar, Farhad and Plana-Ripoll, Oleguer and Plass, Dietrich and Polinder, Suzanne and Popova, Svetlana and Postma, Maarten J and Pourshams, Akram and Poustchi, Hossein and Prabhakaran, Dorairaj and Prakash, Swayam and Prakash, V and Purcell, Caroline A and Purwar, Manorama B and Qorbani, Mostafa and Quistberg, D Alex and Radfar, Amir and Rafay, Anwar and Rafiei, Alireza and Rahim, Fakher and Rahimi, Kazem and Rahimi-Movaghar, Afarin and Rahimi-Movaghar, Vafa and Rahman, Mahfuzar and Rahman, Mohammad Hifz ur and Rahman, Muhammad Aziz and Rahman, Sajjad Ur and Rai, Rajesh Kumar and Rajati, Fatemeh and Ram, Usha and Ranjan, Prabhat and Ranta, Anna and Rao, Puja C and Rawaf, David Laith and Rawaf, Salman and Reddy, K Srinath and Reiner, Robert C and Reinig, Nickolas and Reitsma, Marissa Bettay and Remuzzi, Giuseppe and Renzaho, Andre M N and Resnikoff, Serge and Rezaei, Satar and Rezai, Mohammad Sadegh and Ribeiro, Antonio Luiz P and Roberts, Nicholas L S and Robinson, Stephen R and Roever, Leonardo and Ronfani, Luca and Roshandel, Gholamreza and Rostami, Ali and Roth, Gregory A and Roy, Ambuj and Rubagotti, Enrico and Sachdev, Perminder S and Sadat, Nafis and Saddik, Basema and Sadeghi, Ehsan and Saeedi Moghaddam, Sahar and Safari, Hosein and Safari, Yahya and Safari-Faramani, Roya and Safdarian, Mahdi and Safi, Sare and Safiri, Saeid and Sagar, Rajesh and Sahebkar, Amirhossein and Sahraian, Mohammad Ali and Sajadi, Haniye Sadat and Salam, Nasir and Salama, Joseph S and Salamati, Payman and Saleem, Komal and Saleem, Zikria and Salimi, Yahya and Salomon, Joshua A and Salvi, Sundeep Santosh and Salz, Inbal and Samy, Abdallah M and Sanabria, Juan and Sang, Yingying and Santomauro, Damian Francesco and Santos, Itamar S and Santos, João Vasco and Santric Milicevic, Milena M and Sao Jose, Bruno Piassi and Sardana, Mayank and Sarker, Abdur Razzaque and Sarrafzadegan, Nizal and Sartorius, Benn and Sarvi, Shahabeddin and Sathian, Brijesh and Satpathy, Maheswar and Sawant, Arundhati R and Sawhney, Monika and Saxena, Sonia and Saylan, Mete and Schaeffner, Elke and Schmidt, Maria Inês and Schneider, Ione J C and Schöttker, Ben and Schwebel, David C and Schwendicke, Falk and Scott, James G and Sekerija, Mario and Sepanlou, Sadaf G and Serván-Mori, Edson and Seyedmousavi, Seyedmojtaba and Shabaninejad, Hosein and Shafieesabet, Azadeh and Shahbazi, Mehdi and Shaheen, Amira A and Shaikh, Masood Ali and Shams-Beyranvand, Mehran and Shamsi, Mohammadbagher and Shamsizadeh, Morteza and Sharafi, Heidar and Sharafi, Kiomars and Sharif, Mehdi and Sharif-Alhoseini, Mahdi and Sharma, Meenakshi and Sharma, Rajesh and She, Jun and Sheikh, Aziz and Shi, Peilin and Shibuya, Kenji and Shigematsu, Mika and Shiri, Rahman and Shirkoohi, Reza and Shishani, Kawkab and Shiue, Ivy and Shokraneh, Farhad and Shoman, Haitham and Shrime, Mark G and Si, Si and Siabani, Soraya and Siddiqi, Tariq J and Sigfusdottir, Inga Dora and Sigurvinsdottir, Rannveig and Silva, João Pedro and Silveira, Dayane Gabriele Alves and Singam, Narayana Sarma Venkata and Singh, Jasvinder A and Singh, Narinder Pal and Singh, Virendra and Sinha, Dhirendra Narain and Skiadaresi, Eirini and Slepak, Erica Leigh N and Sliwa, Karen and Smith, David L and Smith, Mari and Soares Filho, Adauto Martins and Sobaih, Badr Hasan and Sobhani, Soheila and Sobngwi, Eugène and Soneji, Samir S and Soofi, Moslem and Soosaraei, Masoud and Sorensen, Reed J D and Soriano, Joan B and Soyiri, Ireneous N and Sposato, Luciano A and Sreeramareddy, Chandrashekhar T and Srinivasan, Vinay and Stanaway, Jeffrey D and Stein, Dan J and Steiner, Caitlyn and Steiner, Timothy J and Stokes, Mark A and Stovner, Lars Jacob and Subart, Michelle L and Sudaryanto, Agus and Sufiyan, Mu'awiyyah Babale and Sunguya, Bruno F and Sur, Patrick John and Sutradhar, Ipsita and Sykes, Bryan L and Sylte, Dillon O and Tabarés-Seisdedos, Rafael and Tadakamadla, Santosh Kumar and Tadesse, Birkneh Tilahun and Tandon, Nikhil and Tassew, Segen Gebremeskel and Tavakkoli, Mohammad and Taveira, Nuno and Taylor, Hugh R and Tehrani-Banihashemi, Arash and Tekalign, Tigist Gashaw and Tekelemedhin, Shishay Wahdey and Tekle, Merhawi Gebremedhin and Temesgen, Habtamu and Temsah, Mohamad-Hani and Temsah, Omar and Terkawi, Abdullah Sulieman and Teweldemedhin, Mebrahtu and Thankappan, Kavumpurathu Raman and Thomas, Nihal and Tilahun, Binyam and To, Quyen G and Tonelli, Marcello and Topor-Madry, Roman and Topouzis, Fotis and Torre, Anna E and Tortajada-Girbés, Miguel and Touvier, Mathilde and Tovani-Palone, Marcos Roberto and Towbin, Jeffrey A and Tran, Bach Xuan and Tran, Khanh Bao and Troeger, Christopher E and Truelsen, Thomas Clement and Tsilimbaris, Miltiadis K and Tsoi, Derrick and Tudor Car, Lorainne and Tuzcu, E Murat and Ukwaja, Kingsley N and Ullah, Irfan and Undurraga, Eduardo A and Unutzer, Jurgen and Updike, Rachel L and Usman, Muhammad Shariq and Uthman, Olalekan A and Vaduganathan, Muthiah and Vaezi, Afsane and Valdez, Pascual R and Varughese, Santosh and Vasankari, Tommi Juhani and Venketasubramanian, Narayanaswamy and Villafaina, Santos and Violante, Francesco S and Vladimirov, Sergey Konstantinovitch and Vlassov, Vasily and Vollset, Stein Emil and Vosoughi, Kia and Vujcic, Isidora S and Wagnew, Fasil Shiferaw and Waheed, Yasir and Waller, Stephen G and Wang, Yafeng and Wang, Yuan-Pang and Weiderpass, Elisabete and Weintraub, Robert G and Weiss, Daniel J and Weldegebreal, Fitsum and Weldegwergs, Kidu Gidey and Werdecker, Andrea and West, T Eoin and Whiteford, Harvey A and Widecka, Justyna and Wijeratne, Tissa and Wilner, Lauren B and Wilson, Shadrach and Winkler, Andrea Sylvia and Wiyeh, Alison B and Wiysonge, Charles Shey and Wolfe, Charles D A and Woolf, Anthony D and Wu, Shouling and Wu, Yun-Chun and Wyper, Grant M A and Xavier, Denis and Xu, Gelin and Yadgir, Simon and Yadollahpour, Ali and Yahyazadeh Jabbari, Seyed Hossein and Yamada, Tomohide and Yan, Lijing L and Yano, Yuichiro and Yaseri, Mehdi and Yasin, Yasin Jemal and Yeshaneh, Alex and Yimer, Ebrahim M and Yip, Paul and Yisma, Engida and Yonemoto, Naohiro and Yoon, Seok-Jun and Yotebieng, Marcel and Younis, Mustafa Z and Yousefifard, Mahmoud and Yu, Chuanhua and Zadnik, Vesna and Zaidi, Zoubida and Zaman, Sojib Bin and Zamani, Mohammad and Zare, Zohreh and Zeleke, Ayalew Jejaw and Zenebe, Zerihun Menlkalew and Zhang, Kai and Zhao, Zheng and Zhou, Maigeng and Zodpey, Sanjay and Zucker, Inbar and Vos, Theo and Murray, Christopher J L},
	month = nov,
	year = {2018},
	pages = {1789--1858},
}

@article{hiligsmann_health_2013,
	title = {Health economics in the field of osteoarthritis: {An} {Expert}'s consensus paper from the {European} {Society} for {Clinical} and {Economic} {Aspects} of {Osteoporosis} and {Osteoarthritis} ({ESCEO})},
	volume = {43},
	issn = {00490172},
	shorttitle = {Health economics in the field of osteoarthritis},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0049017213001510},
	doi = {10.1016/j.semarthrit.2013.07.003},
	language = {en},
	number = {3},
	urldate = {2022-06-08},
	journal = {Seminars in Arthritis and Rheumatism},
	author = {Hiligsmann, Mickaël and Cooper, Cyrus and Arden, Nigel and Boers, Maarten and Branco, Jaime C. and Luisa Brandi, Maria and Bruyère, Olivier and Guillemin, Francis and Hochberg, Marc C. and Hunter, David J. and Kanis, John A. and Kvien, Tore K. and Laslop, Andrea and Pelletier, Jean-Pierre and Pinto, Daniel and Reiter-Niesert, Susanne and Rizzoli, René and Rovati, Lucio C. and Severens, Johan L. (Hans) and Silverman, Stuart and Tsouderos, Yannis and Tugwell, Peter and Reginster, Jean-Yves},
	month = dec,
	year = {2013},
	pages = {303--313},
}

@article{boer_deciphering_2021,
	title = {Deciphering osteoarthritis genetics across 826,690 individuals from 9 populations},
	volume = {184},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867421009417},
	doi = {10.1016/j.cell.2021.07.038},
	language = {en},
	number = {18},
	urldate = {2022-06-08},
	journal = {Cell},
	author = {Boer, Cindy G. and Hatzikotoulas, Konstantinos and Southam, Lorraine and Stefánsdóttir, Lilja and Zhang, Yanfei and Coutinho de Almeida, Rodrigo and Wu, Tian T. and Zheng, Jie and Hartley, April and Teder-Laving, Maris and Skogholt, Anne Heidi and Terao, Chikashi and Zengini, Eleni and Alexiadis, George and Barysenka, Andrei and Bjornsdottir, Gyda and Gabrielsen, Maiken E. and Gilly, Arthur and Ingvarsson, Thorvaldur and Johnsen, Marianne B. and Jonsson, Helgi and Kloppenburg, Margreet and Luetge, Almut and Lund, Sigrun H. and Mägi, Reedik and Mangino, Massimo and Nelissen, Rob R.G.H.H. and Shivakumar, Manu and Steinberg, Julia and Takuwa, Hiroshi and Thomas, Laurent F. and Tuerlings, Margo and Babis, George C. and Cheung, Jason Pui Yin and Kang, Jae Hee and Kraft, Peter and Lietman, Steven A. and Samartzis, Dino and Slagboom, P. Eline and Stefansson, Kari and Thorsteinsdottir, Unnur and Tobias, Jonathan H. and Uitterlinden, André G. and Winsvold, Bendik and Zwart, John-Anker and Davey Smith, George and Sham, Pak Chung and Thorleifsson, Gudmar and Gaunt, Tom R. and Morris, Andrew P. and Valdes, Ana M. and Tsezou, Aspasia and Cheah, Kathryn S.E. and Ikegawa, Shiro and Hveem, Kristian and Esko, Tõnu and Wilkinson, J. Mark and Meulenbelt, Ingrid and Lee, Ming Ta Michael and van Meurs, Joyce B.J. and Styrkársdóttir, Unnur and Zeggini, Eleftheria and Loughlin, John and Arden, Nigel and Birrell, Fraser and Carr, Andrew and Deloukas, Panos and Doherty, Michael and McCaskie, Andrew W. and Ollier, William E.R. and Rai, Ashok and Ralston, Stuart H. and Spector, Tim D. and Wallis, Gillian A. and Martinsen, Amy E. and Willer, Cristen and Fors, Egil Andreas and Mundal, Ingunn and Hagen, Knut and Nilsen, Kristian Bernhard and Lie, Marie Udnesseter and Børte, Sigrid and Brumpton, Ben and Nielsen, Jonas Bille and Fritsche, Lars G. and Zhou, Wei and Heuch, Ingrid and Storheim, Kjersti and Tyrpenou, Evangelos and Koukakis, Athanasios and Chytas, Dimitrios and Evangelopoulos, Dimitrios Stergios and Efstathios, Chronopoulos and Pneumaticos, Spiros and Nikolaou, Vasileios S. and Malizos, Konstantinos and Anastasopoulou, Lydia and Abecasis, Goncalo and Baras, Aris and Cantor, Michael and Coppola, Giovanni and Deubler, Andrew and Economides, Aris and Lotta, Luca A. and Overton, John D. and Reid, Jeffrey G. and Shuldiner, Alan and Karalis, Katia and Siminovitch, Katherine and Beechert, Christina and Forsythe, Caitlin and Fuller, Erin D. and Gu, Zhenhua and Lattari, Michael and Lopez, Alexander and Schleicher, Thomas D. and Padilla, Maria Sotiropoulos and Widom, Louis and Wolf, Sarah E. and Pradhan, Manasi and Manoochehri, Kia and Bai, Xiaodong and Balasubramanian, Suganthi and Boutkov, Boris and Eom, Gisu and Habegger, Lukas and Hawes, Alicia and Krasheninina, Olga and Lanche, Rouel and Mansfield, Adam J. and Maxwell, Evan K. and Nafde, Mona and O’Keeffe, Sean and Orelus, Max and Panea, Razvan and Polanco, Tommy and Rasool, Ayesha and Salerno, William and Staples, Jeffrey C. and Li, Dadong and Sharma, Deepika and Banerjee, Ilanjana and Bovijn, Jonas and Locke, Adam and Verweij, Niek and Haas, Mary and Hindy, George and De, Tanima and Akbari, Parsa and Sosina, Olukayode and Ferreira, Manuel A.R. and Jones, Marcus B. and Mighty, Jason and LeBlanc, Michelle G. and Mitnaul, Lyndon J.},
	month = sep,
	year = {2021},
	pages = {4784--4818.e17},
}

@article{cooper_risk_2000,
	title = {Risk factors for the incidence and progression of radiographic knee osteoarthritis},
	volume = {43},
	issn = {00043591, 15290131},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/1529-0131(200005)43:5<995::AID-ANR6>3.0.CO;2-1},
	doi = {10.1002/1529-0131(200005)43:5<995::AID-ANR6>3.0.CO;2-1},
	number = {5},
	urldate = {2022-06-08},
	journal = {Arthritis \& Rheumatism},
	author = {Cooper, Cyrus and Snow, Shelagh and McAlindon, Timothy E. and Kellingray, Samantha and Stuart, Brenda and Coggon, David and Dieppe, Paul A.},
	month = may,
	year = {2000},
	pages = {995},
}

@article{zhang_methodologic_2010,
	title = {Methodologic challenges in studying risk factors for progression of knee osteoarthritis},
	volume = {62},
	issn = {2151464X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/acr.20287},
	doi = {10.1002/acr.20287},
	language = {en},
	number = {11},
	urldate = {2022-06-08},
	journal = {Arthritis Care \& Research},
	author = {Zhang, Yuqing and Niu, Jingbo and Felson, David T. and Choi, Hyon K. and Nevitt, Michael and Neogi, Tuhina},
	month = nov,
	year = {2010},
	pages = {1527--1532},
}

@article{veronese_osteoarthritis_2016,
	title = {Osteoarthritis and mortality: {A} prospective cohort study and systematic review with meta-analysis},
	volume = {46},
	issn = {00490172},
	shorttitle = {Osteoarthritis and mortality},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0049017216300087},
	doi = {10.1016/j.semarthrit.2016.04.002},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Seminars in Arthritis and Rheumatism},
	author = {Veronese, Nicola and Cereda, Emanuele and Maggi, Stefania and Luchini, Claudio and Solmi, Marco and Smith, Toby and Denkinger, Michael and Hurley, Michael and Thompson, Trevor and Manzato, Enzo and Sergi, Giuseppe and Stubbs, Brendon},
	month = oct,
	year = {2016},
	pages = {160--167},
}

@article{styrkarsdottir_meta-analysis_2018,
	title = {Meta-analysis of {Icelandic} and {UK} data sets identifies missense variants in {SMO}, {IL11}, {COL11A1} and 13 more new loci associated with osteoarthritis},
	volume = {50},
	issn = {1061-4036, 1546-1718},
	url = {http://www.nature.com/articles/s41588-018-0247-0},
	doi = {10.1038/s41588-018-0247-0},
	language = {en},
	number = {12},
	urldate = {2022-06-08},
	journal = {Nature Genetics},
	author = {Styrkarsdottir, Unnur and Lund, Sigrun H. and Thorleifsson, Gudmar and Zink, Florian and Stefansson, Olafur A. and Sigurdsson, Jon K. and Juliusson, Kristinn and Bjarnadottir, Kristbjörg and Sigurbjornsdottir, Sara and Jonsson, Stefan and Norland, Kristjan and Stefansdottir, Lilja and Sigurdsson, Asgeir and Sveinbjornsson, Gardar and Oddsson, Asmundur and Bjornsdottir, Gyda and Gudmundsson, Reynir L. and Halldorsson, Gisli H. and Rafnar, Thorunn and Jonsdottir, Ingileif and Steingrimsson, Eirikur and Norddahl, Gudmundur L. and Masson, Gisli and Sulem, Patrick and Jonsson, Helgi and Ingvarsson, Thorvaldur and Gudbjartsson, Daniel F. and Thorsteinsdottir, Unnur and Stefansson, Kari},
	month = dec,
	year = {2018},
	pages = {1681--1687},
}

@article{arcogen_consortium_identification_2019,
	title = {Identification of new therapeutic targets for osteoarthritis through genome-wide analyses of {UK} {Biobank} data},
	volume = {51},
	issn = {1061-4036, 1546-1718},
	url = {http://www.nature.com/articles/s41588-018-0327-1},
	doi = {10.1038/s41588-018-0327-1},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Nature Genetics},
	author = {{arcOGEN Consortium} and Tachmazidou, Ioanna and Hatzikotoulas, Konstantinos and Southam, Lorraine and Esparza-Gordillo, Jorge and Haberland, Valeriia and Zheng, Jie and Johnson, Toby and Koprulu, Mine and Zengini, Eleni and Steinberg, Julia and Wilkinson, Jeremy M. and Bhatnagar, Sahir and Hoffman, Joshua D. and Buchan, Natalie and Süveges, Dániel and Yerges-Armstrong, Laura and Smith, George Davey and Gaunt, Tom R. and Scott, Robert A. and McCarthy, Linda C. and Zeggini, Eleftheria},
	month = feb,
	year = {2019},
	pages = {230--236},
}

@article{zengini_genome-wide_2018,
	title = {Genome-wide analyses using {UK} {Biobank} data provide insights into the genetic architecture of osteoarthritis},
	volume = {50},
	issn = {1061-4036, 1546-1718},
	url = {http://www.nature.com/articles/s41588-018-0079-y},
	doi = {10.1038/s41588-018-0079-y},
	language = {en},
	number = {4},
	urldate = {2022-06-08},
	journal = {Nature Genetics},
	author = {Zengini, Eleni and Hatzikotoulas, Konstantinos and Tachmazidou, Ioanna and Steinberg, Julia and Hartwig, Fernando P. and Southam, Lorraine and Hackinger, Sophie and Boer, Cindy G. and Styrkarsdottir, Unnur and Gilly, Arthur and Suveges, Daniel and Killian, Britt and Ingvarsson, Thorvaldur and Jonsson, Helgi and Babis, George C. and McCaskie, Andrew and Uitterlinden, Andre G. and van Meurs, Joyce B. J. and Thorsteinsdottir, Unnur and Stefansson, Kari and Davey Smith, George and Wilkinson, Jeremy M. and Zeggini, Eleftheria},
	month = apr,
	year = {2018},
	pages = {549--558},
}

@article{choi_tutorial:_2020,
	title = {Tutorial: a guide to performing polygenic risk score analyses},
	volume = {15},
	issn = {1754-2189, 1750-2799},
	shorttitle = {Tutorial},
	url = {http://www.nature.com/articles/s41596-020-0353-1},
	doi = {10.1038/s41596-020-0353-1},
	language = {en},
	number = {9},
	urldate = {2022-06-08},
	journal = {Nature Protocols},
	author = {Choi, Shing Wan and Mak, Timothy Shin-Heng and O’Reilly, Paul F.},
	month = sep,
	year = {2020},
	pages = {2759--2772},
}

@article{jostins_genetic_2011,
	title = {Genetic risk prediction in complex disease},
	volume = {20},
	issn = {1460-2083, 0964-6906},
	url = {https://academic.oup.com/hmg/article-lookup/doi/10.1093/hmg/ddr378},
	doi = {10.1093/hmg/ddr378},
	language = {en},
	number = {R2},
	urldate = {2022-06-08},
	journal = {Human Molecular Genetics},
	author = {Jostins, Luke and Barrett, Jeffrey C.},
	month = oct,
	year = {2011},
	pages = {R182--R188},
}

@article{wray_research_2014,
	title = {Research {Review}: {Polygenic} methods and their application to psychiatric traits},
	volume = {55},
	issn = {00219630},
	shorttitle = {Research {Review}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/jcpp.12295},
	doi = {10.1111/jcpp.12295},
	language = {en},
	number = {10},
	urldate = {2022-06-08},
	journal = {Journal of Child Psychology and Psychiatry},
	author = {Wray, Naomi R. and Lee, Sang Hong and Mehta, Divya and Vinkhuyzen, Anna A.E. and Dudbridge, Frank and Middeldorp, Christel M.},
	month = oct,
	year = {2014},
	pages = {1068--1087},
}

@article{so_exploring_2017,
	title = {Exploring the predictive power of polygenic scores derived from genome-wide association studies: a study of 10 complex traits},
	issn = {1367-4803, 1460-2059},
	shorttitle = {Exploring the predictive power of polygenic scores derived from genome-wide association studies},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btw745},
	doi = {10.1093/bioinformatics/btw745},
	language = {en},
	urldate = {2022-06-08},
	journal = {Bioinformatics},
	author = {So, Hon-Cheong and Sham, Pak C.},
	month = jan,
	year = {2017},
	pages = {btw745},
}

@article{capriotti_predicting_2006,
	title = {Predicting the insurgence of human genetic diseases associated to single point protein mutations with support vector machines and evolutionary information},
	volume = {22},
	issn = {1367-4803, 1460-2059},
	url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btl423},
	doi = {10.1093/bioinformatics/btl423},
	language = {en},
	number = {22},
	urldate = {2022-06-08},
	journal = {Bioinformatics},
	author = {Capriotti, E. and Calabrese, R. and Casadio, R.},
	month = nov,
	year = {2006},
	pages = {2729--2734},
}

@article{cruz_applications_2006,
	title = {Applications of {Machine} {Learning} in {Cancer} {Prediction} and {Prognosis}},
	volume = {2},
	issn = {1176-9351, 1176-9351},
	url = {http://journals.sagepub.com/doi/10.1177/117693510600200030},
	doi = {10.1177/117693510600200030},
	abstract = {Machine learning is a branch of artificial intelligence that employs a variety of statistical, probabilistic and optimization techniques that allows computers to “learn” from past examples and to detect hard-to-discern patterns from large, noisy or complex data sets. This capability is particularly well-suited to medical applications, especially those that depend on complex proteomic and genomic measurements. As a result, machine learning is frequently used in cancer diagnosis and detection. More recently machine learning has been applied to cancer prognosis and prediction. This latter approach is particularly interesting as it is part of a growing trend towards personalized, predictive medicine. In assembling this review we conducted a broad survey of the different types of machine learning methods being used, the types of data being integrated and the performance of these methods in cancer prediction and prognosis. A number of trends are noted, including a growing dependence on protein biomarkers and microarray data, a strong bias towards applications in prostate and breast cancer, and a heavy reliance on “older” technologies such artificial neural networks (ANNs) instead of more recently developed or more easily interpretable machine learning methods. A number of published studies also appear to lack an appropriate level of validation or testing. Among the better designed and validated studies it is clear that machine learning methods can be used to substantially (15–25\%) improve the accuracy of predicting cancer susceptibility, recurrence and mortality. At a more fundamental level, it is also evident that machine learning is also helping to improve our basic understanding of cancer development and progression.},
	language = {en},
	urldate = {2022-06-08},
	journal = {Cancer Informatics},
	author = {Cruz, Joseph A. and Wishart, David S.},
	month = jan,
	year = {2006},
	pages = {117693510600200},
}

@inproceedings{palaniappan_intelligent_2008,
	title = {Intelligent heart disease prediction system using data mining techniques},
	doi = {10.1109/AICCSA.2008.4493524},
	abstract = {The healthcare industry collects huge amounts of healthcare data which, unfortunately, are not ";mined"; to discover hidden information for effective decision making. Discovery of hidden patterns and relationships often goes unexploited. Advanced data mining techniques can help remedy this situation. This research has developed a prototype Intelligent Heart Disease Prediction System (IHDPS) using data mining techniques, namely, Decision Trees, Naive Bayes and Neural Network. Results show that each technique has its unique strength in realizing the objectives of the defined mining goals. IHDPS can answer complex ";what if"; queries which traditional decision support systems cannot. Using medical profiles such as age, sex, blood pressure and blood sugar it can predict the likelihood of patients getting a heart disease. It enables significant knowledge, e.g. patterns, relationships between medical factors related to heart disease, to be established. IHDPS is Web-based, user-friendly, scalable, reliable and expandable. It is implemented on the .NET platform.},
	booktitle = {2008 {IEEE}/{ACS} {International} {Conference} on {Computer} {Systems} and {Applications}},
	author = {Palaniappan, Sellappan and Awang, Rafiah},
	month = mar,
	year = {2008},
	note = {ISSN: 2161-5330},
	keywords = {Cardiac disease, Data mining, Medical services, Industrial relations, Mining industry, Decision making, Prototypes, Intelligent networks, Decision trees, Neural networks},
	pages = {108--115},
}

@article{yu_application_2010,
	title = {Application of support vector machine modeling for prediction of common diseases: the case of diabetes and pre-diabetes},
	volume = {10},
	issn = {1472-6947},
	shorttitle = {Application of support vector machine modeling for prediction of common diseases},
	url = {https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/1472-6947-10-16},
	doi = {10.1186/1472-6947-10-16},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Yu, Wei and Liu, Tiebin and Valdez, Rodolfo and Gwinn, Marta and Khoury, Muin J},
	month = dec,
	year = {2010},
	pages = {16},
}

@article{zhang_multi-modal_2012,
	title = {Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in {Alzheimer}'s disease},
	volume = {59},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S105381191101144X},
	doi = {10.1016/j.neuroimage.2011.09.069},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {NeuroImage},
	author = {Zhang, Daoqiang and Shen, Dinggang},
	month = jan,
	year = {2012},
	pages = {895--907},
}

@article{lopez_single_2018,
	title = {Single {Nucleotide} {Polymorphism} relevance learning with {Random} {Forests} for {Type} 2 diabetes risk prediction},
	volume = {85},
	issn = {09333657},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0933365717300684},
	doi = {10.1016/j.artmed.2017.09.005},
	language = {en},
	urldate = {2022-06-08},
	journal = {Artificial Intelligence in Medicine},
	author = {López, Beatriz and Torrent-Fontbona, Ferran and Viñas, Ramón and Fernández-Real, José Manuel},
	month = apr,
	year = {2018},
	pages = {43--49},
}

@article{montanez_deep_2018,
	title = {Deep {Learning} {Classification} of {Polygenic} {Obesity} using {Genome} {Wide} {Association} {Study} {SNPs}},
	url = {http://arxiv.org/abs/1804.03198},
	abstract = {In this paper, association results from genome-wide association studies (GWAS) are combined with a deep learning framework to test the predictive capacity of statistically significant single nucleotide polymorphism (SNPs) associated with obesity phenotype. Our approach demonstrates the potential of deep learning as a powerful framework for GWAS analysis that can capture information about SNPs and the important interactions between them. Basic statistical methods and techniques for the analysis of genetic SNP data from population-based genome-wide studies have been considered. Statistical association testing between individual SNPs and obesity was conducted under an additive model using logistic regression. Four subsets of loci after quality-control (QC) and association analysis were selected: P-values lower than 1x10-5 (5 SNPs), 1x10-4 (32 SNPs), 1x10-3 (248 SNPs) and 1x10-2 (2465 SNPs). A deep learning classifier is initialised using these sets of SNPs and fine-tuned to classify obese and non-obese observations. Using a deep learning classifier model and genetic variants with P-value {\textless} 1x10-2 (2465 SNPs) it was possible to obtain results (SE=0.9604, SP=0.9712, Gini=0.9817, LogLoss=0.1150, AUC=0.9908 and MSE=0.0300). As the P-value increased, an evident deterioration in performance was observed. Results demonstrate that single SNP analysis fails to capture the cumulative effect of less significant variants and their overall contribution to the outcome in disease prediction, which is captured using a deep learning framework.},
	urldate = {2022-06-08},
	journal = {arXiv:1804.03198 [cs, q-bio]},
	author = {Montañez, Casimiro Adays Curbelo and Fergus, Paul and Montañez, Almudena Curbelo and Chalmers, Carl},
	month = aug,
	year = {2018},
	note = {arXiv: 1804.03198},
	keywords = {Computer Science - Computers and Society, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning, Quantitative Biology - Genomics},
}

@article{bronstein_geometric_2017,
	title = {Geometric deep learning: going beyond {Euclidean} data},
	volume = {34},
	issn = {1053-5888, 1558-0792},
	shorttitle = {Geometric deep learning},
	url = {http://arxiv.org/abs/1611.08097},
	doi = {10.1109/MSP.2017.2693418},
	abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.},
	number = {4},
	urldate = {2022-06-08},
	journal = {IEEE Signal Processing Magazine},
	author = {Bronstein, Michael M. and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	month = jul,
	year = {2017},
	note = {arXiv: 1611.08097},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {18--42},
}

@article{sperduti_supervised_1997,
	title = {Supervised neural networks for the classification of structures},
	volume = {8},
	issn = {1045-9227, 1941-0093},
	url = {https://ieeexplore.ieee.org/document/572108/},
	doi = {10.1109/72.572108},
	number = {3},
	urldate = {2022-06-08},
	journal = {IEEE Transactions on Neural Networks},
	author = {Sperduti, A. and Starita, A.},
	month = may,
	year = {1997},
	pages = {714--735},
}

@inproceedings{gori_new_2005,
	title = {A new model for learning in graph domains},
	volume = {2},
	doi = {10.1109/IJCNN.2005.1555942},
	abstract = {In several applications the information is naturally represented by graphs. Traditional approaches cope with graphical data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in this way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model.},
	booktitle = {Proceedings. 2005 {IEEE} {International} {Joint} {Conference} on {Neural} {Networks}, 2005.},
	author = {Gori, M. and Monfardini, G. and Scarselli, F.},
	month = jul,
	year = {2005},
	note = {ISSN: 2161-4407},
	keywords = {Neural networks, Focusing, Application software, Machine learning, Recurrent neural networks, Encoding, Data structures, Machine learning algorithms, Tree graphs, Software engineering},
	pages = {729--734 vol. 2},
}

@article{xu_how_2019,
	title = {How {Powerful} are {Graph} {Neural} {Networks}?},
	url = {http://arxiv.org/abs/1810.00826},
	abstract = {Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.},
	urldate = {2022-06-08},
	journal = {arXiv:1810.00826 [cs, stat]},
	author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
	month = feb,
	year = {2019},
	note = {arXiv: 1810.00826},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
}

@article{velickovic_graph_2018,
	title = {Graph {Attention} {Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	urldate = {2022-06-08},
	journal = {arXiv:1710.10903 [cs, stat]},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	month = feb,
	year = {2018},
	note = {arXiv: 1710.10903},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@article{atwood_diffusion-convolutional_2016,
	title = {Diffusion-{Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1511.02136},
	abstract = {We present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data. Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graph-structured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on the GPU. Through several experiments with real structured datasets, we demonstrate that DCNNs are able to outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.},
	urldate = {2022-06-08},
	journal = {arXiv:1511.02136 [cs]},
	author = {Atwood, James and Towsley, Don},
	month = jul,
	year = {2016},
	note = {arXiv: 1511.02136},
	keywords = {Computer Science - Machine Learning},
}

@article{kipf_semi-supervised_2017,
	title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
	urldate = {2022-06-08},
	journal = {arXiv:1609.02907 [cs, stat]},
	author = {Kipf, Thomas N. and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv: 1609.02907},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{defferrard_convolutional_2017,
	title = {Convolutional {Neural} {Networks} on {Graphs} with {Fast} {Localized} {Spectral} {Filtering}},
	url = {http://arxiv.org/abs/1606.09375},
	abstract = {In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
	urldate = {2022-06-08},
	journal = {arXiv:1606.09375 [cs, stat]},
	author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
	month = feb,
	year = {2017},
	note = {arXiv: 1606.09375},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{li_adaptive_2018,
	title = {Adaptive {Graph} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1801.03226},
	abstract = {Graph Convolutional Neural Networks (Graph CNNs) are generalizations of classical CNNs to handle graph data such as molecular data, point could and social networks. Current filters in graph CNNs are built for fixed and shared graph structure. However, for most real data, the graph structures varies in both size and connectivity. The paper proposes a generalized and flexible graph CNN taking data of arbitrary graph structure as input. In that way a task-driven adaptive graph is learned for each graph data while training. To efficiently learn the graph, a distance metric learning is proposed. Extensive experiments on nine graph-structured datasets have demonstrated the superior performance improvement on both convergence speed and predictive accuracy.},
	urldate = {2022-06-08},
	journal = {arXiv:1801.03226 [cs, stat]},
	author = {Li, Ruoyu and Wang, Sheng and Zhu, Feiyun and Huang, Junzhou},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.03226},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{veselkov_hyperfoods:_2019,
	title = {{HyperFoods}: {Machine} intelligent mapping of cancer-beating molecules in foods},
	volume = {9},
	issn = {2045-2322},
	shorttitle = {{HyperFoods}},
	url = {http://www.nature.com/articles/s41598-019-45349-y},
	doi = {10.1038/s41598-019-45349-y},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Scientific Reports},
	author = {Veselkov, Kirill and Gonzalez, Guadalupe and Aljifri, Shahad and Galea, Dieter and Mirnezami, Reza and Youssef, Jozef and Bronstein, Michael and Laponogov, Ivan},
	month = dec,
	year = {2019},
	pages = {9237},
}

@article{knyazev_spectral_2018,
	title = {Spectral {Multigraph} {Networks} for {Discovering} and {Fusing} {Relationships} in {Molecules}},
	url = {http://arxiv.org/abs/1811.09595},
	abstract = {Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Chebyshev GCNs restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We model learned edges with abstract meaning and experiment with different ways to fuse the representations extracted from annotated and learned edges, achieving competitive results on a variety of chemical classification benchmarks.},
	urldate = {2022-06-08},
	journal = {arXiv:1811.09595 [cs, stat]},
	author = {Knyazev, Boris and Lin, Xiao and Amer, Mohamed R. and Taylor, Graham W.},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.09595},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
}

@article{yan_spatial_2018,
	title = {Spatial {Temporal} {Graph} {Convolutional} {Networks} for {Skeleton}-{Based} {Action} {Recognition}},
	url = {http://arxiv.org/abs/1801.07455},
	abstract = {Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.},
	urldate = {2022-06-08},
	journal = {arXiv:1801.07455 [cs]},
	author = {Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.07455},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@techreport{ghosal_biologically_2021,
	type = {preprint},
	title = {A {Biologically} {Interpretable} {Graph} {Convolutional} {Network} to {Link} {Genetic} {Risk} {Pathways} and {Neuroimaging} {Markers} of {Disease}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2021.05.28.446066},
	abstract = {A
            bstract
          
          We propose a novel end-to-end framework for whole-brain and whole-genome imaging-genetics. Our genetics network uses hierarchical graph convolution and pooling operations to embed subject-level data onto a low-dimensional latent space. The hierarchical network implicitly tracks the convergence of genetic risk across well-established biological pathways, while an attention mechanism automatically identifies the salient edges of this network at the subject level. In parallel, our imaging network projects multimodal data onto a set of latent embeddings. For interpretability, we implement a Bayesian feature selection strategy to extract the discriminative imaging biomarkers; these feature weights are optimized alongside the other model parameters. We couple the imaging and genetic embeddings with a predictor network, to ensure that the learned representations are linked to phenotype. We evaluate our framework on a schizophrenia dataset that includes two functional MRI paradigms and gene scores derived from Single Nucleotide Polymorphism data. Using repeated 10-fold cross-validation, we show that our imaging-genetics fusion achieves the better classification performance than state-of-the-art baselines. In an exploratory analysis, we further show that the biomarkers identified by our model are reproducible and closely associated with deficits in schizophrenia.},
	language = {en},
	urldate = {2022-06-08},
	institution = {Bioinformatics},
	author = {Ghosal, Sayan and Chen, Qiang and Pergola, Giulio and Goldman, Aaron L. and Ulrich, William and Weinberger, Daniel R. and Venkataraman, Archana},
	month = may,
	year = {2021},
	doi = {10.1101/2021.05.28.446066},
}

@article{ying_gnnexplainer:_2019,
	title = {{GNNExplainer}: {Generating} {Explanations} for {Graph} {Neural} {Networks}},
	shorttitle = {{GNNExplainer}},
	url = {http://arxiv.org/abs/1903.03894},
	abstract = {Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs.GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models, and explaining predictions made by GNNs remains unsolved. Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GNNExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1\% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.},
	urldate = {2022-06-08},
	journal = {arXiv:1903.03894 [cs, stat]},
	author = {Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
	month = nov,
	year = {2019},
	note = {arXiv: 1903.03894},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sudlow_uk_2015,
	title = {{UK} {Biobank}: {An} {Open} {Access} {Resource} for {Identifying} the {Causes} of a {Wide} {Range} of {Complex} {Diseases} of {Middle} and {Old} {Age}},
	volume = {12},
	issn = {1549-1676},
	shorttitle = {{UK} {Biobank}},
	url = {https://dx.plos.org/10.1371/journal.pmed.1001779},
	doi = {10.1371/journal.pmed.1001779},
	language = {en},
	number = {3},
	urldate = {2022-06-08},
	journal = {PLOS Medicine},
	author = {Sudlow, Cathie and Gallacher, John and Allen, Naomi and Beral, Valerie and Burton, Paul and Danesh, John and Downey, Paul and Elliott, Paul and Green, Jane and Landray, Martin and Liu, Bette and Matthews, Paul and Ong, Giok and Pell, Jill and Silman, Alan and Young, Alan and Sprosen, Tim and Peakman, Tim and Collins, Rory},
	month = mar,
	year = {2015},
	pages = {e1001779},
}

 @misc{who, 
 url={https://icd.who.int/en}, 
 journal={World Health Organization}, 
 publisher={World Health Organization},
 } 

@article{chen_revisiting_2021,
	title = {Revisiting the genome-wide significance threshold for common variant {GWAS}},
	volume = {11},
	issn = {2160-1836},
	url = {https://academic.oup.com/g3journal/article/doi/10.1093/g3journal/jkaa056/6080665},
	doi = {10.1093/g3journal/jkaa056},
	abstract = {Abstract
            Over the last decade, GWAS meta-analyses have used a strict P-value threshold of 5 × 10−8 to classify associations as significant. Here, we use our current understanding of frequently studied traits including lipid levels, height, and BMI to revisit this genome-wide significance threshold. We compare the performance of studies using the P = 5 × 10−8 threshold in terms of true and false positive rate to other multiple testing strategies: (1) less stringent P-value thresholds, (2) controlling the FDR with the Benjamini–Hochberg and Benjamini–Yekutieli procedure, and (3) controlling the Bayesian FDR with posterior probabilities. We applied these procedures to re-analyze results from the Global Lipids and GIANT GWAS meta-analysis consortia and supported them with extensive simulation that mimics the empirical data. We observe in simulated studies with sample sizes ∼20,000 and \&gt;120,000 that relaxing the P-value threshold to 5 × 10−7 increased discovery at the cost of 18\% and 8\% of additional loci being false positive results, respectively. FDR and Bayesian FDR are well controlled for both sample sizes with a few exceptions that disappear under a less stringent definition of true positives and the two approaches yield similar results. Our work quantifies the value of using a relaxed P-value threshold in large studies to increase their true positive discovery but also show the excess false positive rates due to such actions in modest-sized studies. These results may guide investigators considering different thresholds in replication studies and downstream work such as gene-set enrichment or pathway analysis. Finally, we demonstrate the viability of FDR-controlling procedures in GWAS.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {G3 Genes{\textbar}Genomes{\textbar}Genetics},
	author = {Chen, Zhongsheng and Boehnke, Michael and Wen, Xiaoquan and Mukherjee, Bhramar},
	editor = {De Koning, D -J},
	month = apr,
	year = {2021},
	pages = {jkaa056},
}

@article{wilk_probability_1968,
	title = {Probability plotting methods for the analysis for the analysis of data},
	volume = {55},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/55.1.1},
	doi = {10.1093/biomet/55.1.1},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Biometrika},
	author = {Wilk, M. B. and Gnanadesikan, R.},
	year = {1968},
	pages = {1--17},
}

@article{marees_tutorial_2018,
	title = {A tutorial on conducting genome-wide association studies: {Quality} control and statistical analysis},
	volume = {27},
	issn = {10498931},
	shorttitle = {A tutorial on conducting genome-wide association studies},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/mpr.1608},
	doi = {10.1002/mpr.1608},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {International Journal of Methods in Psychiatric Research},
	author = {Marees, Andries T. and de Kluiver, Hilde and Stringer, Sven and Vorspan, Florence and Curis, Emmanuel and Marie-Claire, Cynthia and Derks, Eske M.},
	month = jun,
	year = {2018},
	pages = {e1608},
}

@article{janes_optimal_2005,
	title = {The optimal ratio of cases to controls for estimating the classification accuracy of a biomarker},
	volume = {7},
	issn = {1465-4644, 1468-4357},
	url = {https://academic.oup.com/biostatistics/article-lookup/doi/10.1093/biostatistics/kxj018},
	doi = {10.1093/biostatistics/kxj018},
	language = {en},
	number = {3},
	urldate = {2022-06-08},
	journal = {Biostatistics},
	author = {Janes, H.},
	month = dec,
	year = {2005},
	pages = {456--468},
}

@article{tibshirani_regression_1996,
	title = {Regression {Shrinkage} and {Selection} {Via} the {Lasso}},
	volume = {58},
	issn = {00359246},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1996.tb02080.x},
	doi = {10.1111/j.2517-6161.1996.tb02080.x},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Tibshirani, Robert},
	month = jan,
	year = {1996},
	pages = {267--288},
}

@article{fung_feature_2004,
	title = {A {Feature} {Selection} {Newton} {Method} for {Support} {Vector} {Machine} {Classification}},
	volume = {28},
	issn = {1573-2894},
	url = {https://doi.org/10.1023/B:COAP.0000026884.66338.df},
	doi = {10.1023/B:COAP.0000026884.66338.df},
	abstract = {A fast Newton method, that suppresses input space features, is proposed for a linear programming formulation of support vector machine classifiers. The proposed stand-alone method can handle classification problems in very high dimensional spaces, such as 28,032 dimensions, and generates a classifier that depends on very few input features, such as 7 out of the original 28,032. The method can also handle problems with a large number of data points and requires no specialized linear programming packages but merely a linear equation solver. For nonlinear kernel classifiers, the method utilizes a minimal number of kernel functions in the classifier that it generates.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Computational Optimization and Applications},
	author = {Fung, Glenn M. and Mangasarian, O.L.},
	month = jul,
	year = {2004},
	pages = {185--202},
}

@inproceedings{hu_embedding_2017,
	address = {Singapore Singapore},
	title = {On {Embedding} {Uncertain} {Graphs}},
	isbn = {9781450349185},
	url = {https://dl.acm.org/doi/10.1145/3132847.3132885},
	doi = {10.1145/3132847.3132885},
	language = {en},
	urldate = {2022-06-08},
	booktitle = {Proceedings of the 2017 {ACM} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Hu, Jiafeng and Cheng, Reynold and Huang, Zhipeng and Fang, Yixang and Luo, Siqiang},
	month = nov,
	year = {2017},
	pages = {157--166},
}

@article{monti_geometric_2016,
	title = {Geometric deep learning on graphs and manifolds using mixture model {CNNs}},
	url = {http://arxiv.org/abs/1611.08402},
	abstract = {Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches.},
	urldate = {2022-06-08},
	journal = {arXiv:1611.08402 [cs]},
	author = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodolà, Emanuele and Svoboda, Jan and Bronstein, Michael M.},
	month = dec,
	year = {2016},
	note = {arXiv: 1611.08402},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{zhu_survey_2022,
	title = {A {Survey} on {Graph} {Structure} {Learning}: {Progress} and {Opportunities}},
	shorttitle = {A {Survey} on {Graph} {Structure} {Learning}},
	url = {http://arxiv.org/abs/2103.03036},
	abstract = {Graphs are widely used to describe real-world objects and their interactions. Graph Neural Networks (GNNs) as a de facto model for analyzing graphstructured data, are highly sensitive to the quality of the given graph structures. Therefore, noisy or incomplete graphs often lead to unsatisfactory representations and prevent us from fully understanding the mechanism underlying the system. In pursuit of an optimal graph structure for downstream tasks, recent studies have sparked an effort around the central theme of Graph Structure Learning (GSL), which aims to jointly learn an optimized graph structure and corresponding graph representations. In the presented survey, we broadly review recent progress in GSL methods. Specifically, we first formulate a general pipeline of GSL and review state-of-the-art methods classified by the way of modeling graph structures, followed by applications of GSL across domains. Finally, we point out some issues in current studies and discuss future directions.},
	urldate = {2022-06-08},
	journal = {arXiv:2103.03036 [cs]},
	author = {Zhu, Yanqiao and Xu, Weizhi and Zhang, Jinghao and Du, Yuanqi and Zhang, Jieyu and Liu, Qiang and Yang, Carl and Wu, Shu},
	month = feb,
	year = {2022},
	note = {arXiv: 2103.03036},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@article{bentley_complexity_1977,
	title = {The complexity of finding fixed-radius near neighbors},
	volume = {6},
	issn = {00200190},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0020019077900709},
	doi = {10.1016/0020-0190(77)90070-9},
	language = {en},
	number = {6},
	urldate = {2022-06-08},
	journal = {Information Processing Letters},
	author = {Bentley, Jon L. and Stanat, Donald F. and Williams, E.Hollins},
	month = dec,
	year = {1977},
	pages = {209--212},
}

@article{holland_stochastic_1983,
	title = {Stochastic blockmodels: {First} steps},
	volume = {5},
	issn = {03788733},
	shorttitle = {Stochastic blockmodels},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0378873383900217},
	doi = {10.1016/0378-8733(83)90021-7},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Social Networks},
	author = {Holland, Paul W. and Laskey, Kathryn Blackmond and Leinhardt, Samuel},
	month = jun,
	year = {1983},
	pages = {109--137},
}

@article{zhang_bayesian_2019,
	title = {Bayesian {Graph} {Convolutional} {Neural} {Networks} for {Semi}-{Supervised} {Classification}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	url = {https://aimagazine.org/ojs/index.php/AAAI/article/view/4531},
	doi = {10.1609/aaai.v33i01.33015829},
	abstract = {Recently, techniques for applying convolutional neural networks to graph-structured data have emerged. Graph convolutional neural networks (GCNNs) have been used to address node and graph classification and matrix completion. Although the performance has been impressive, the current implementations have limited capability to incorporate uncertainty in the graph structure. Almost all GCNNs process a graph as though it is a ground-truth depiction of the relationship between nodes, but often the graphs employed in applications are themselves derived from noisy data or modelling assumptions. Spurious edges may be included; other edges may be missing between nodes that have very strong relationships. In this paper we adopt a Bayesian approach, viewing the observed graph as a realization from a parametric family of random graphs. We then target inference of the joint posterior of the random graph parameters and the node (or graph) labels. We present the Bayesian GCNN framework and develop an iterative learning procedure for the case of assortative mixed-membership stochastic block models. We present the results of experiments that demonstrate that the Bayesian formulation can provide better performance when there are very few labels available during the training process.},
	urldate = {2022-06-08},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Zhang, Yingxue and Pal, Soumyasundar and Coates, Mark and Ustebay, Deniz},
	month = jul,
	year = {2019},
	pages = {5829--5836},
}

@article{elinas_variational_2020,
	title = {Variational {Inference} for {Graph} {Convolutional} {Networks} in the {Absence} of {Graph} {Data} and {Adversarial} {Settings}},
	url = {http://arxiv.org/abs/1906.01852},
	abstract = {We propose a framework that lifts the capabilities of graph convolutional networks (GCNs) to scenarios where no input graph is given and increases their robustness to adversarial attacks. We formulate a joint probabilistic model that considers a prior distribution over graphs along with a GCN-based likelihood and develop a stochastic variational inference algorithm to estimate the graph posterior and the GCN parameters jointly. To address the problem of propagating gradients through latent variables drawn from discrete distributions, we use their continuous relaxations known as Concrete distributions. We show that, on real datasets, our approach can outperform state-of-the-art Bayesian and non-Bayesian graph neural network algorithms on the task of semi-supervised classification in the absence of graph data and when the network structure is subjected to adversarial perturbations.},
	urldate = {2022-06-08},
	journal = {arXiv:1906.01852 [cs, stat]},
	author = {Elinas, Pantelis and Bonilla, Edwin V. and Tiao, Louis},
	month = oct,
	year = {2020},
	note = {arXiv: 1906.01852},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hamilton_inductive_2018,
	title = {Inductive {Representation} {Learning} on {Large} {Graphs}},
	url = {http://arxiv.org/abs/1706.02216},
	abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
	urldate = {2022-06-08},
	journal = {arXiv:1706.02216 [cs, stat]},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	month = sep,
	year = {2018},
	note = {arXiv: 1706.02216},
	keywords = {Computer Science - Social and Information Networks, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wang_graph_2021,
	address = {Ljubljana Slovenia},
	title = {Graph {Structure} {Estimation} {Neural} {Networks}},
	isbn = {9781450383127},
	url = {https://dl.acm.org/doi/10.1145/3442381.3449952},
	doi = {10.1145/3442381.3449952},
	language = {en},
	urldate = {2022-06-08},
	booktitle = {Proceedings of the {Web} {Conference} 2021},
	publisher = {ACM},
	author = {Wang, Ruijia and Mou, Shuai and Wang, Xiao and Xiao, Wanpeng and Ju, Qi and Shi, Chuan and Xie, Xing},
	month = apr,
	year = {2021},
	pages = {342--353},
}

@article{dempster_maximum_1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} {Via} the \textit{{EM}} {Algorithm}},
	volume = {39},
	issn = {00359246},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.2517-6161.1977.tb01600.x},
	doi = {10.1111/j.2517-6161.1977.tb01600.x},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	month = sep,
	year = {1977},
	pages = {1--22},
}

@article{jordan_introduction_1999,
	title = {An {Introduction} to {Variational} {Methods} for {Graphical} {Models}},
	volume = {37},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1007665907178},
	doi = {10.1023/A:1007665907178},
	abstract = {This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Machine Learning},
	author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
	month = nov,
	year = {1999},
	pages = {183--233},
}

@article{jaakkola_bayesian_2000,
	title = {Bayesian parameter estimation via variational methods},
	volume = {10},
	issn = {1573-1375},
	url = {https://doi.org/10.1023/A:1008932416310},
	doi = {10.1023/A:1008932416310},
	abstract = {We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model. This approach is readily extended to binary graphical model with complete observations. For graphical models with incomplete observations we utilize an additional variational transformation and again obtain a closed form approximation to the posterior. Finally, we show that the dual of the regression problem gives a latent variable density model, the variational formulation of which leads to exactly solvable EM updates.},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Statistics and Computing},
	author = {Jaakkola, Tommi S. and Jordan, Michael I.},
	month = jan,
	year = {2000},
	pages = {25--37},
}

@article{jensen_sur_1906,
	title = {Sur les fonctions convexes et les inégalités entre les valeurs moyennes},
	volume = {30},
	issn = {0001-5962},
	url = {http://projecteuclid.org/euclid.acta/1485887155},
	doi = {10.1007/BF02418571},
	language = {en},
	number = {0},
	urldate = {2022-06-08},
	journal = {Acta Mathematica},
	author = {Jensen, J. L. W. V.},
	year = {1906},
	pages = {175--193},
}

@article{tzikas_variational_2008,
	title = {The variational approximation for {Bayesian} inference},
	volume = {25},
	issn = {1053-5888},
	abstract = {The influence of this Thomas Bayes\&\#39; work was immense. It was from here that \&quot;Bayesian\&quot; ideas first spread through the mathematical world, as Bayes\&\#39;s own article was ignored until 1780 and played no important role in scientific},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Tzikas, Dimitris G. and Likas, Aristidis C. and Galatsanos, Nikolaos P.},
	year = {2008},
	pages = {131},
}

@incollection{neal_view_1998,
	address = {Dordrecht},
	title = {A {View} of the {Em} {Algorithm} that {Justifies} {Incremental}, {Sparse}, and other {Variants}},
	isbn = {9789401150149},
	url = {https://doi.org/10.1007/978-94-011-5014-9_12},
	abstract = {The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible.},
	language = {en},
	urldate = {2022-06-08},
	booktitle = {Learning in {Graphical} {Models}},
	publisher = {Springer Netherlands},
	author = {Neal, Radford M. and Hinton, Geoffrey E.},
	editor = {Jordan, Michael I.},
	year = {1998},
	doi = {10.1007/978-94-011-5014-9_12},
	pages = {355--368},
}

@phdthesis{haj_stochastics_2019,
	type = {phdthesis},
	title = {Stochastics blockmodels, classifications and applications},
	url = {https://tel.archives-ouvertes.fr/tel-02926379},
	abstract = {This PhD thesis focuses on the analysis of weighted networks, where each edge is associated to a weight representing its strength. We introduce an extension of the binary stochastic block model (SBM), called binomial stochastic block model (bSBM). This question is motivated by the study of co-citation networks in a context of text mining where data is represented by a graph. Nodes are words and each edge joining two words is weighted by the number of documents included in the corpus simultaneously citing this pair of words. We develop an inference method based on a variational maximization algorithm (VEM) to estimate the parameters of the modelas well as to classify the words of the network. Then, we adopt a method based on maximizing an integrated classification likelihood (ICL) criterion to select the optimal model and the number of clusters. Otherwise, we develop a variational approach to analyze the given network. Then we compare the two approaches. Applications based on real data are adopted to show the effectiveness of the two methods as well as to compare them. Finally, we develop a SBM model with several attributes to deal with node-weighted networks. We motivate this approach by an application that aims at the development of a tool to help the specification of different cognitive treatments performed by the brain during the preparation of the writing.},
	language = {en},
	urldate = {2022-06-08},
	school = {Université de Poitiers ; Université Libanaise},
	author = {Haj, Abir El},
	month = nov,
	year = {2019},
}

@article{haj_estimation_2020,
	title = {Estimation in a binomial stochastic blockmodel for a weighted graph by a variational expectation maximization algorithm},
	issn = {0361-0918, 1532-4141},
	url = {https://www.tandfonline.com/doi/full/10.1080/03610918.2020.1743858},
	doi = {10.1080/03610918.2020.1743858},
	language = {en},
	urldate = {2022-06-08},
	journal = {Communications in Statistics - Simulation and Computation},
	author = {Haj, Abir El and Slaoui, Yousri and Louis, Pierre-Yves and Khraibani, Zaher},
	month = may,
	year = {2020},
	pages = {1--20},
}

@article{schwarz_estimating_1978,
	title = {Estimating the {Dimension} of a {Model}},
	volume = {6},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-6/issue-2/Estimating-the-Dimension-of-a-Model/10.1214/aos/1176344136.full},
	doi = {10.1214/aos/1176344136},
	number = {2},
	urldate = {2022-06-08},
	journal = {The Annals of Statistics},
	author = {Schwarz, Gideon},
	month = mar,
	year = {1978},
}

@article{daudin_mixture_2008,
	title = {A mixture model for random graphs},
	volume = {18},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-007-9046-7},
	doi = {10.1007/s11222-007-9046-7},
	abstract = {The Erdös–Rényi model of a network is simple and possesses many explicit expressions for average and asymptotic properties, but it does not fit well to real-world networks. The vertices of those networks are often structured in unknown classes (functionally related proteins or social communities) with different connectivity properties. The stochastic block structures model was proposed for this purpose in the context of social sciences, using a Bayesian approach. We consider the same model in a frequentest statistical framework. We give the degree distribution and the clustering coefficient associated with this model, a variational method to estimate its parameters and a model selection criterion to select the number of classes. This estimation procedure allows us to deal with large networks containing thousands of vertices. The method is used to uncover the modular structure of a network of enzymatic reactions.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Statistics and Computing},
	author = {Daudin, J.-J. and Picard, F. and Robin, S.},
	month = jun,
	year = {2008},
	pages = {173--183},
}

@book{proakis_digital_1996,
	address = {London},
	edition = {3. ed},
	series = {Prentice {Hall} international editions},
	title = {Digital signal processing: principles, algorithms, and applications},
	isbn = {9780133942897},
	shorttitle = {Digital signal processing},
	language = {eng},
	publisher = {Prentice-Hall International (UK)},
	author = {Proakis, John G. and Manolakis, Dimitris G.},
	year = {1996},
}

@article{stahlschmidt_multimodal_2022,
	title = {Multimodal deep learning for biomedical data fusion: a review},
	volume = {23},
	issn = {1467-5463, 1477-4054},
	shorttitle = {Multimodal deep learning for biomedical data fusion},
	url = {https://academic.oup.com/bib/article/doi/10.1093/bib/bbab569/6516346},
	doi = {10.1093/bib/bbab569},
	abstract = {Abstract
            Biomedical data are becoming increasingly multimodal and thereby capture the underlying complex relationships among biological processes. Deep learning (DL)-based data fusion strategies are a popular approach for modeling these nonlinear relationships. Therefore, we review the current state-of-the-art of such methods and propose a detailed taxonomy that facilitates more informed choices of fusion strategies for biomedical applications, as well as research on novel methods. By doing so, we find that deep fusion strategies often outperform unimodal and shallow approaches. Additionally, the proposed subcategories of fusion strategies show different advantages and drawbacks. The review of current methods has shown that, especially for intermediate fusion strategies, joint representation learning is the preferred approach as it effectively models the complex interactions of different levels of biological organization. Finally, we note that gradual fusion, based on prior biological knowledge or on search strategies, is a promising future research path. Similarly, utilizing transfer learning might overcome sample size limitations of multimodal data sets. As these data sets become increasingly available, multimodal DL approaches present the opportunity to train holistic models that can learn the complex regulatory dynamics behind health and disease.},
	language = {en},
	number = {2},
	urldate = {2022-06-08},
	journal = {Briefings in Bioinformatics},
	author = {Stahlschmidt, Sören Richard and Ulfenborg, Benjamin and Synnergren, Jane},
	month = mar,
	year = {2022},
	pages = {bbab569},
}

@article{gaudillo_machine_2019,
	title = {Machine learning approach to single nucleotide polymorphism-based asthma prediction},
	volume = {14},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0225574},
	doi = {10.1371/journal.pone.0225574},
	language = {en},
	number = {12},
	urldate = {2022-06-08},
	journal = {PLOS ONE},
	author = {Gaudillo, Joverlyn and Rodriguez, Jae Joseph Russell and Nazareno, Allen and Baltazar, Lei Rigi and Vilela, Julianne and Bulalacao, Rommel and Domingo, Mario and Albia, Jason},
	editor = {Hernandez-Lemus, Enrique},
	month = dec,
	year = {2019},
	pages = {e0225574},
}

@article{fawcett_introduction_2006,
	series = {{ROC} {Analysis} in {Pattern} {Recognition}},
	title = {An introduction to {ROC} analysis},
	volume = {27},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S016786550500303X},
	doi = {10.1016/j.patrec.2005.10.010},
	abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
	language = {en},
	number = {8},
	urldate = {2022-06-08},
	journal = {Pattern Recognition Letters},
	author = {Fawcett, Tom},
	month = jun,
	year = {2006},
	keywords = {ROC analysis, Classifier evaluation, Evaluation metrics},
	pages = {861--874},
}

@article{zou_receiver-operating_2007,
	title = {Receiver-{Operating} {Characteristic} {Analysis} for {Evaluating} {Diagnostic} {Tests} and {Predictive} {Models}},
	volume = {115},
	url = {https://www.ahajournals.org/doi/10.1161/circulationaha.105.594929},
	doi = {10.1161/CIRCULATIONAHA.105.594929},
	number = {5},
	urldate = {2022-06-08},
	journal = {Circulation},
	author = {Zou, Kelly H. and O’Malley, A. James and Mauri, Laura},
	month = feb,
	year = {2007},
	keywords = {statistics, ROC curve, sensitivity and specificity, diagnosis, tests},
	pages = {654--657},
}

@article{naaman_tight_2021,
	title = {On the tight constant in the multivariate {Dvoretzky}–{Kiefer}–{Wolfowitz} inequality},
	volume = {173},
	issn = {01677152},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016771522100050X},
	doi = {10.1016/j.spl.2021.109088},
	language = {en},
	urldate = {2022-06-08},
	journal = {Statistics \& Probability Letters},
	author = {Naaman, Michael},
	month = jun,
	year = {2021},
	pages = {109088},
}

@article{dudbridge_power_2013,
	title = {Power and {Predictive} {Accuracy} of {Polygenic} {Risk} {Scores}},
	volume = {9},
	issn = {1553-7404},
	url = {https://dx.plos.org/10.1371/journal.pgen.1003348},
	doi = {10.1371/journal.pgen.1003348},
	language = {en},
	number = {3},
	urldate = {2022-06-08},
	journal = {PLoS Genetics},
	author = {Dudbridge, Frank},
	editor = {Wray, Naomi R.},
	month = mar,
	year = {2013},
	pages = {e1003348},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {1558-2256},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	number = {11},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	keywords = {Neural networks, Pattern recognition, Machine learning, Optical character recognition software, Character recognition, Feature extraction, Multi-layer neural network, Optical computing, Hidden Markov models, Principal component analysis},
	pages = {2278--2324},
}

@article{pendergrass_use_2011,
	title = {The use of phenome-wide association studies ({PheWAS}) for exploration of novel genotype-phenotype relationships and pleiotropy discovery},
	volume = {35},
	issn = {07410395},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/gepi.20589},
	doi = {10.1002/gepi.20589},
	language = {en},
	number = {5},
	urldate = {2022-06-08},
	journal = {Genetic Epidemiology},
	author = {Pendergrass, S.A. and Brown-Gentry, K. and Dudek, S.M. and Torstenson, E.S. and Ambite, J.L. and Avery, C.L. and Buyske, S. and Cai, C. and Fesinmeyer, M.D. and Haiman, C. and Heiss, G. and Hindorff, L.A. and Hsu, C.-N. and Jackson, R.D. and Kooperberg, C. and Le Marchand, L. and Lin, Y. and Matise, T.C. and Moreland, L. and Monroe, K. and Reiner, A.P. and Wallace, R. and Wilkens, L.R. and Crawford, D.C. and Ritchie, M.D.},
	month = jul,
	year = {2011},
	pages = {410--422},
}

@article{watanabe_global_2019,
	title = {A global overview of pleiotropy and genetic architecture in complex traits},
	volume = {51},
	issn = {1546-1718},
	doi = {10.1038/s41588-019-0481-0},
	abstract = {After a decade of genome-wide association studies (GWASs), fundamental questions in human genetics, such as the extent of pleiotropy across the genome and variation in genetic architecture across traits, are still unanswered. The current availability of hundreds of GWASs provides a unique opportunity to address these questions. We systematically analyzed 4,155 publicly available GWASs. For a subset of well-powered GWASs on 558 traits, we provide an extensive overview of pleiotropy and genetic architecture. We show that trait-associated loci cover more than half of the genome, and 90\% of these overlap with loci from multiple traits. We find that potential causal variants are enriched in coding and flanking regions, as well as in regulatory elements, and show variation in polygenicity and discoverability of traits. Our results provide insights into how genetic variation contributes to trait variation. All GWAS results can be queried and visualized at the GWAS ATLAS resource ( https://atlas.ctglab.nl ).},
	language = {eng},
	number = {9},
	journal = {Nature Genetics},
	author = {Watanabe, Kyoko and Stringer, Sven and Frei, Oleksandr and Umićević Mirkov, Maša and de Leeuw, Christiaan and Polderman, Tinca J. C. and van der Sluis, Sophie and Andreassen, Ole A. and Neale, Benjamin M. and Posthuma, Danielle},
	month = sep,
	year = {2019},
	pmid = {31427789},
	keywords = {Genetic Pleiotropy, Genetics, Population, Genome-Wide Association Study, Humans, Multifactorial Inheritance, Phenotype, Polymorphism, Single Nucleotide, Quantitative Trait Loci},
	pages = {1339--1348},
}

@article{jensen_hip_2008,
	title = {Hip osteoarthritis: influence of work with heavy lifting, climbing stairs or ladders, or combining kneeling/squatting with heavy lifting},
	volume = {65},
	issn = {1351-0711},
	shorttitle = {Hip osteoarthritis},
	url = {https://oem.bmj.com/lookup/doi/10.1136/oem.2006.032409},
	doi = {10.1136/oem.2006.032409},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Occupational and Environmental Medicine},
	author = {Jensen, L K},
	month = jan,
	year = {2008},
	pages = {6--19},
}

@article{maruthur_diabetes_2016,
	title = {Diabetes {Medications} as {Monotherapy} or {Metformin}-{Based} {Combination} {Therapy} for {Type} 2 {Diabetes}: {A} {Systematic} {Review} and {Meta}-analysis},
	volume = {164},
	issn = {0003-4819},
	shorttitle = {Diabetes {Medications} as {Monotherapy} or {Metformin}-{Based} {Combination} {Therapy} for {Type} 2 {Diabetes}},
	url = {http://annals.org/article.aspx?doi=10.7326/M15-2650},
	doi = {10.7326/M15-2650},
	language = {en},
	number = {11},
	urldate = {2022-06-08},
	journal = {Annals of Internal Medicine},
	author = {Maruthur, Nisa M. and Tseng, Eva and Hutfless, Susan and Wilson, Lisa M. and Suarez-Cuervo, Catalina and Berger, Zackary and Chu, Yue and Iyoha, Emmanuel and Segal, Jodi B. and Bolen, Shari},
	month = jun,
	year = {2016},
	pages = {740},
}

@article{barrett_diabetes-mediated_2017,
	title = {Diabetes-mediated myelopoiesis and the relationship to cardiovascular risk: {Diabetes} myelopoiesis and cardiovascular risk},
	volume = {1402},
	issn = {00778923},
	shorttitle = {Diabetes-mediated myelopoiesis and the relationship to cardiovascular risk},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/nyas.13462},
	doi = {10.1111/nyas.13462},
	language = {en},
	number = {1},
	urldate = {2022-06-08},
	journal = {Annals of the New York Academy of Sciences},
	author = {Barrett, Tessa J. and Murphy, Andrew J. and Goldberg, Ira J. and Fisher, Edward A.},
	month = aug,
	year = {2017},
	pages = {31--42},
}

@article{vos_years_2012,
	title = {Years lived with disability ({YLDs}) for 1160 sequelae of 289 diseases and injuries 1990–2010: a systematic analysis for the {Global} {Burden} of {Disease} {Study} 2010},
	volume = {380},
	issn = {01406736},
	shorttitle = {Years lived with disability ({YLDs}) for 1160 sequelae of 289 diseases and injuries 1990–2010},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673612617292},
	doi = {10.1016/S0140-6736(12)61729-2},
	language = {en},
	number = {9859},
	urldate = {2022-06-08},
	journal = {The Lancet},
	author = {Vos, Theo and Flaxman, Abraham D and Naghavi, Mohsen and Lozano, Rafael and Michaud, Catherine and Ezzati, Majid and Shibuya, Kenji and Salomon, Joshua A and Abdalla, Safa and Aboyans, Victor and Abraham, Jerry and Ackerman, Ilana and Aggarwal, Rakesh and Ahn, Stephanie Y and Ali, Mohammed K and AlMazroa, Mohammad A and Alvarado, Miriam and Anderson, H Ross and Anderson, Laurie M and Andrews, Kathryn G and Atkinson, Charles and Baddour, Larry M and Bahalim, Adil N and Barker-Collo, Suzanne and Barrero, Lope H and Bartels, David H and Basáñez, Maria-Gloria and Baxter, Amanda and Bell, Michelle L and Benjamin, Emelia J and Bennett, Derrick and Bernabé, Eduardo and Bhalla, Kavi and Bhandari, Bishal and Bikbov, Boris and Abdulhak, Aref Bin and Birbeck, Gretchen and Black, James A and Blencowe, Hannah and Blore, Jed D and Blyth, Fiona and Bolliger, Ian and Bonaventure, Audrey and Boufous, Soufiane and Bourne, Rupert and Boussinesq, Michel and Braithwaite, Tasanee and Brayne, Carol and Bridgett, Lisa and Brooker, Simon and Brooks, Peter and Brugha, Traolach S and Bryan-Hancock, Claire and Bucello, Chiara and Buchbinder, Rachelle and Buckle, Geoffrey and Budke, Christine M and Burch, Michael and Burney, Peter and Burstein, Roy and Calabria, Bianca and Campbell, Benjamin and Canter, Charles E and Carabin, Hélène and Carapetis, Jonathan and Carmona, Loreto and Cella, Claudia and Charlson, Fiona and Chen, Honglei and Cheng, Andrew Tai-Ann and Chou, David and Chugh, Sumeet S and Coffeng, Luc E and Colan, Steven D and Colquhoun, Samantha and Colson, K Ellicott and Condon, John and Connor, Myles D and Cooper, Leslie T and Corriere, Matthew and Cortinovis, Monica and de Vaccaro, Karen Courville and Couser, William and Cowie, Benjamin C and Criqui, Michael H and Cross, Marita and Dabhadkar, Kaustubh C and Dahiya, Manu and Dahodwala, Nabila and Damsere-Derry, James and Danaei, Goodarz and Davis, Adrian and De Leo, Diego and Degenhardt, Louisa and Dellavalle, Robert and Delossantos, Allyne and Denenberg, Julie and Derrett, Sarah and Des Jarlais, Don C and Dharmaratne, Samath D and Dherani, Mukesh and Diaz-Torne, Cesar and Dolk, Helen and Dorsey, E Ray and Driscoll, Tim and Duber, Herbert and Ebel, Beth and Edmond, Karen and Elbaz, Alexis and Ali, Suad Eltahir and Erskine, Holly and Erwin, Patricia J and Espindola, Patricia and Ewoigbokhan, Stalin E and Farzadfar, Farshad and Feigin, Valery and Felson, David T and Ferrari, Alize and Ferri, Cleusa P and Fèvre, Eric M and Finucane, Mariel M and Flaxman, Seth and Flood, Louise and Foreman, Kyle and Forouzanfar, Mohammad H and Fowkes, Francis Gerry R and Franklin, Richard and Fransen, Marlene and Freeman, Michael K and Gabbe, Belinda J and Gabriel, Sherine E and Gakidou, Emmanuela and Ganatra, Hammad A and Garcia, Bianca and Gaspari, Flavio and Gillum, Richard F and Gmel, Gerhard and Gosselin, Richard and Grainger, Rebecca and Groeger, Justina and Guillemin, Francis and Gunnell, David and Gupta, Ramyani and Haagsma, Juanita and Hagan, Holly and Halasa, Yara A and Hall, Wayne and Haring, Diana and Haro, Josep Maria and Harrison, James E and Havmoeller, Rasmus and Hay, Roderick J and Higashi, Hideki and Hill, Catherine and Hoen, Bruno and Hoffman, Howard and Hotez, Peter J and Hoy, Damian and Huang, John J and Ibeanusi, Sydney E and Jacobsen, Kathryn H and James, Spencer L and Jarvis, Deborah and Jasrasaria, Rashmi and Jayaraman, Sudha and Johns, Nicole and Jonas, Jost B and Karthikeyan, Ganesan and Kassebaum, Nicholas and Kawakami, Norito and Keren, Andre and Khoo, Jon-Paul and King, Charles H and Knowlton, Lisa Marie and Kobusingye, Olive and Koranteng, Adofo and Krishnamurthi, Rita and Lalloo, Ratilal and Laslett, Laura L and Lathlean, Tim and Leasher, Janet L and Lee, Yong Yi and Leigh, James and Lim, Stephen S and Limb, Elizabeth and Lin, John Kent and Lipnick, Michael and Lipshultz, Steven E and Liu, Wei and Loane, Maria and Ohno, Summer Lockett and Lyons, Ronan and Ma, Jixiang and Mabweijano, Jacqueline and MacIntyre, Michael F and Malekzadeh, Reza and Mallinger, Leslie and Manivannan, Sivabalan and Marcenes, Wagner and March, Lyn and Margolis, David J and Marks, Guy B and Marks, Robin and Matsumori, Akira and Matzopoulos, Richard and Mayosi, Bongani M and McAnulty, John H and McDermott, Mary M and McGill, Neil and McGrath, John and Medina-Mora, Maria Elena and Meltzer, Michele and Memish, Ziad A and Mensah, George A and Merriman, Tony R and Meyer, Ana-Claire and Miglioli, Valeria and Miller, Matthew and Miller, Ted R and Mitchell, Philip B and Mocumbi, Ana Olga and Moffitt, Terrie E and Mokdad, Ali A and Monasta, Lorenzo and Montico, Marcella and Moradi-Lakeh, Maziar and Moran, Andrew and Morawska, Lidia and Mori, Rintaro and Murdoch, Michele E and Mwaniki, Michael K and Naidoo, Kovin and Nair, M Nathan and Naldi, Luigi and Narayan, KM Venkat and Nelson, Paul K and Nelson, Robert G and Nevitt, Michael C and Newton, Charles R and Nolte, Sandra and Norman, Paul and Norman, Rosana and O'Donnell, Martin and O'Hanlon, Simon and Olives, Casey and Omer, Saad B and Ortblad, Katrina and Osborne, Richard and Ozgediz, Doruk and Page, Andrew and Pahari, Bishnu and Pandian, Jeyaraj Durai and Rivero, Andrea Panozo and Patten, Scott B and Pearce, Neil and Padilla, Rogelio Perez and Perez-Ruiz, Fernando and Perico, Norberto and Pesudovs, Konrad and Phillips, David and Phillips, Michael R and Pierce, Kelsey and Pion, Sébastien and Polanczyk, Guilherme V and Polinder, Suzanne and Pope, C Arden and Popova, Svetlana and Porrini, Esteban and Pourmalek, Farshad and Prince, Martin and Pullan, Rachel L and Ramaiah, Kapa D and Ranganathan, Dharani and Razavi, Homie and Regan, Mathilda and Rehm, Jürgen T and Rein, David B and Remuzzi, Guiseppe and Richardson, Kathryn and Rivara, Frederick P and Roberts, Thomas and Robinson, Carolyn and De Leòn, Felipe Rodriguez and Ronfani, Luca and Room, Robin and Rosenfeld, Lisa C and Rushton, Lesley and Sacco, Ralph L and Saha, Sukanta and Sampson, Uchechukwu and Sanchez-Riera, Lidia and Sanman, Ella and Schwebel, David C and Scott, James Graham and Segui-Gomez, Maria and Shahraz, Saeid and Shepard, Donald S and Shin, Hwashin and Shivakoti, Rupak and Silberberg, Donald and Singh, David and Singh, Gitanjali M and Singh, Jasvinder A and Singleton, Jessica and Sleet, David A and Sliwa, Karen and Smith, Emma and Smith, Jennifer L and Stapelberg, Nicolas JC and Steer, Andrew and Steiner, Timothy and Stolk, Wilma A and Stovner, Lars Jacob and Sudfeld, Christopher and Syed, Sana and Tamburlini, Giorgio and Tavakkoli, Mohammad and Taylor, Hugh R and Taylor, Jennifer A and Taylor, William J and Thomas, Bernadette and Thomson, W Murray and Thurston, George D and Tleyjeh, Imad M and Tonelli, Marcello and Towbin, Jeffrey A and Truelsen, Thomas and Tsilimbaris, Miltiadis K and Ubeda, Clotilde and Undurraga, Eduardo A and van der Werf, Marieke J and van Os, Jim and Vavilala, Monica S and Venketasubramanian, N and Wang, Mengru and Wang, Wenzhi and Watt, Kerrianne and Weatherall, David J and Weinstock, Martin A and Weintraub, Robert and Weisskopf, Marc G and Weissman, Myrna M and White, Richard A and Whiteford, Harvey and Wiersma, Steven T and Wilkinson, James D and Williams, Hywel C and Williams, Sean RM and Witt, Emma and Wolfe, Frederick and Woolf, Anthony D and Wulf, Sarah and Yeh, Pon-Hsiu and Zaidi, Anita KM and Zheng, Zhi-Jie and Zonies, David and Lopez, Alan D and Murray, Christopher JL},
	month = dec,
	year = {2012},
	pages = {2163--2196},
}

@book{preparata_computational_1985,
	address = {New York, NY},
	title = {Computational {Geometry}},
	isbn = {9781461270102 9781461210986},
	url = {http://link.springer.com/10.1007/978-1-4612-1098-6},
	urldate = {2022-06-08},
	publisher = {Springer New York},
	author = {Preparata, Franco P. and Shamos, Michael Ian},
	year = {1985},
	doi = {10.1007/978-1-4612-1098-6},
}
